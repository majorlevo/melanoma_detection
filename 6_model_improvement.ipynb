{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a681023",
   "metadata": {},
   "source": [
    "# Model Improvement for Melanoma Detection\n",
    "\n",
    "This notebook implements various improvements to our baseline ResNet18 model based on published research and best practices in medical image classification.\n",
    "\n",
    "## Goals:\n",
    "1. Implement state-of-the-art architectures (ResNet50, EfficientNet, DenseNet)\n",
    "2. Apply advanced data augmentation techniques\n",
    "3. Handle class imbalance with weighted loss and sampling\n",
    "4. Optimize hyperparameters using Optuna\n",
    "5. Train and evaluate the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3205375a",
   "metadata": {},
   "source": [
    "## Literature Review & Best Practices\n",
    "\n",
    "### Key Findings from Research:\n",
    "\n",
    "**1. Architecture Selection:**\n",
    "- **EfficientNet** (Tan & Le, 2019): Achieves state-of-the-art accuracy with fewer parameters through compound scaling\n",
    "  - Source: \"EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks\" (ICML 2019)\n",
    "  - Key insight: Balance network depth, width, and resolution for optimal performance\n",
    "\n",
    "- **ResNet50** (He et al., 2016): Deeper networks with residual connections prevent vanishing gradients\n",
    "  - Source: \"Deep Residual Learning for Image Recognition\" (CVPR 2016)\n",
    "  - Proven effective for medical imaging tasks\n",
    "\n",
    "- **DenseNet** (Huang et al., 2017): Dense connections improve feature reuse and gradient flow\n",
    "  - Source: \"Densely Connected Convolutional Networks\" (CVPR 2017)\n",
    "  - Efficient parameter usage for medical images\n",
    "\n",
    "**2. Transfer Learning & Fine-tuning:**\n",
    "- Pre-training on ImageNet provides robust low-level features (Yosinski et al., 2014)\n",
    "- Source: \"How transferable are features in deep neural networks?\" (NIPS 2014)\n",
    "- Strategy: Fine-tune all layers with lower learning rate for better adaptation\n",
    "\n",
    "**3. Data Augmentation for Medical Images:**\n",
    "- **Horizontal/Vertical Flips**: Lesions can appear in any orientation\n",
    "- **Rotation (Â±20Â°)**: Natural variation in image capture angles\n",
    "- **Color Jittering**: Handles lighting variations in dermatoscopy\n",
    "- **RandAugment** (Cubuk et al., 2020): Automated augmentation strategy\n",
    "  - Source: \"RandAugment: Practical automated data augmentation\" (NeurIPS 2020)\n",
    "- **MixUp** (Zhang et al., 2018): Reduces overfitting and improves calibration\n",
    "  - Source: \"mixup: Beyond Empirical Risk Minimization\" (ICLR 2018)\n",
    "\n",
    "**4. Class Imbalance Handling:**\n",
    "- **Weighted Loss**: Penalize misclassification of minority classes more heavily\n",
    "- **Focal Loss** (Lin et al., 2017): Focus on hard examples\n",
    "  - Source: \"Focal Loss for Dense Object Detection\" (ICCV 2017)\n",
    "- **Oversampling**: Balance training distribution with WeightedRandomSampler\n",
    "\n",
    "**5. Melanoma-Specific Insights:**\n",
    "- Input resolution: 224x224 or 299x299 recommended (Esteva et al., 2017)\n",
    "- Source: \"Dermatologist-level classification of skin cancer with deep neural networks\" (Nature 2017)\n",
    "- Multi-scale features important for detecting subtle patterns\n",
    "- Ensemble methods can improve robustness (Haenssle et al., 2018)\n",
    "\n",
    "**6. Hyperparameter Optimization:**\n",
    "- Learning rate: Critical for convergence (typically 1e-4 to 1e-3 for fine-tuning)\n",
    "- Batch size: Trade-off between generalization and training speed\n",
    "- Weight decay: Regularization to prevent overfitting (typically 1e-5 to 1e-4)\n",
    "- Optimizer: Adam or AdamW with cosine annealing scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c3a01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install optuna timm albumentations tensorboard scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392f60d",
   "metadata": {},
   "source": [
    "### Fix for NumPy compatibility error\n",
    "\n",
    "If you get the error: `ValueError: numpy.dtype size changed, may indicate binary incompatibility`\n",
    "\n",
    "This happens when packages were compiled against different NumPy versions. Run this in your terminal from the project root:\n",
    "\n",
    "```powershell\n",
    ".\\.venv\\Scripts\\python.exe -m pip install --upgrade pip\n",
    ".\\.venv\\Scripts\\python.exe -m pip install --upgrade numpy\n",
    ".\\.venv\\Scripts\\python.exe -m pip install --force-reinstall --no-cache-dir scipy pandas matplotlib pillow scikit-learn\n",
    ".\\.venv\\Scripts\\python.exe -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    ".\\.venv\\Scripts\\python.exe -m pip install optuna timm tensorboard seaborn tqdm\n",
    "```\n",
    "\n",
    "Or run this in a notebook cell with `!`:\n",
    "```python\n",
    "!.\\.venv\\Scripts\\python.exe -m pip install --upgrade pip numpy\n",
    "!.\\.venv\\Scripts\\python.exe -m pip install --force-reinstall --no-cache-dir scipy pandas matplotlib pillow scikit-learn\n",
    "!.\\.venv\\Scripts\\python.exe -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!.\\.venv\\Scripts\\python.exe -m pip install optuna timm tensorboard seaborn tqdm\n",
    "```\n",
    "\n",
    "**Important:** After installing, restart the kernel for changes to take effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cf78bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\major\\Documents\\University\\DeepLearning\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import copy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "from torchvision import transforms, models\n",
    "\n",
    "import timm  # PyTorch Image Models for EfficientNet\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7911bf41",
   "metadata": {},
   "source": [
    "## 1. Load Existing Model for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7e6032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\major\\Documents\\University\\DeepLearning\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\major\\Documents\\University\\DeepLearning\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Baseline ResNet18 model loaded successfully\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the baseline ResNet18 model\n",
    "baseline_model = models.resnet18(pretrained=False)\n",
    "num_ftrs = baseline_model.fc.in_features\n",
    "baseline_model.fc = nn.Linear(num_ftrs, 3)\n",
    "\n",
    "if os.path.exists(\"melanoma_model_weights.pth\"):\n",
    "    baseline_model.load_state_dict(torch.load(\"melanoma_model_weights.pth\", map_location=device))\n",
    "    print(\"âœ“ Baseline ResNet18 model loaded successfully\")\n",
    "else:\n",
    "    print(\"âš  Warning: melanoma_model_weights.pth not found. Will train from scratch.\")\n",
    "\n",
    "baseline_model = baseline_model.to(device)\n",
    "baseline_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d46908ea",
   "metadata": {},
   "source": [
    "## 2. Data Pipeline with Advanced Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8790cdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HAM10000Dataset(Dataset):\n",
    "    \"\"\"Dataset class for HAM10000 with flexible augmentation.\"\"\"\n",
    "\n",
    "    def __init__(self, image_dir, ann_dir, image_files, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.ann_dir = ann_dir\n",
    "        self.image_files = image_files\n",
    "        self.transform = transform\n",
    "\n",
    "        # Class mapping from original labels to 3-class groups\n",
    "        self.group_map = {\n",
    "            \"melanoma\": \"melanoma\",\n",
    "            \"basal cell carcinoma\": \"suspicious\",\n",
    "            \"actinic keratoses\": \"suspicious\",\n",
    "            \"melanocytic nevi\": \"benign\",\n",
    "            \"benign keratosis-like lesions\": \"benign\",\n",
    "            \"dermatofibroma\": \"benign\",\n",
    "            \"vascular lesions\": \"benign\",\n",
    "        }\n",
    "\n",
    "        self.group_to_idx = {\"benign\": 0, \"suspicious\": 1, \"melanoma\": 2}\n",
    "        self.idx_to_group = {0: \"benign\", 1: \"suspicious\", 2: \"melanoma\"}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Load annotation\n",
    "        ann_path = os.path.join(self.ann_dir, img_name + \".json\")\n",
    "        try:\n",
    "            with open(ann_path, \"r\") as f:\n",
    "                ann = json.load(f)\n",
    "            original_label = ann[\"objects\"][0][\"classTitle\"]\n",
    "            group_label = self.group_map[original_label]\n",
    "            label = self.group_to_idx[group_label]\n",
    "        except Exception as e:\n",
    "            # Skip corrupted annotations\n",
    "            print(f\"Error loading {ann_path}: {e}\")\n",
    "            label = 0  # Default to benign\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25fef874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_augmentation_transforms(augmentation_level=\"medium\", input_size=224):\n",
    "    \"\"\"\n",
    "    Create augmentation transforms based on research best practices.\n",
    "\n",
    "    Args:\n",
    "        augmentation_level: 'light', 'medium', or 'heavy'\n",
    "        input_size: Target image size (224 or 299)\n",
    "    \"\"\"\n",
    "\n",
    "    # Base transforms for validation/testing\n",
    "    val_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((input_size, input_size)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Training transforms with varying augmentation levels\n",
    "    if augmentation_level == \"light\":\n",
    "        train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((input_size, input_size)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    elif augmentation_level == \"medium\":\n",
    "        train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((input_size, input_size)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomRotation(20),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    else:  # heavy\n",
    "        train_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((int(input_size * 1.1), int(input_size * 1.1))),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.RandomVerticalFlip(p=0.5),\n",
    "                transforms.RandomRotation(30),\n",
    "                transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "                transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.15),\n",
    "                transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return train_transform, val_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32c09cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images found: 10015\n",
      "Train: 6409, Val: 1603, Test: 2003\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset splits\n",
    "image_dir = \"data/ham10000/ds/img\"\n",
    "ann_dir = \"data/ham10000/ds/ann\"\n",
    "\n",
    "# Get all image files\n",
    "all_files = [f for f in os.listdir(image_dir) if f.endswith(\".jpg\")]\n",
    "print(f\"Total images found: {len(all_files)}\")\n",
    "\n",
    "# Split into train/val/test (70/15/15)\n",
    "train_files, test_files = train_test_split(all_files, test_size=0.3, random_state=42)\n",
    "train_files, val_files = train_test_split(train_files, test_size=0.3, random_state=42)  # 0.176 * 0.85 â‰ˆ 0.15\n",
    "\n",
    "print(f\"Train: {len(train_files)}, Val: {len(val_files)}, Test: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5c7423b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set class distribution:\n",
      "  benign: 5152 (80.4%)\n",
      "  suspicious: 545 (8.5%)\n",
      "  melanoma: 711 (11.1%)\n"
     ]
    }
   ],
   "source": [
    "# Analyze class distribution\n",
    "def get_class_distribution(image_files, ann_dir):\n",
    "    \"\"\"Get class distribution for given image files.\"\"\"\n",
    "    group_map = {\n",
    "        \"melanoma\": \"melanoma\",\n",
    "        \"basal cell carcinoma\": \"suspicious\",\n",
    "        \"actinic keratoses\": \"suspicious\",\n",
    "        \"melanocytic nevi\": \"benign\",\n",
    "        \"benign keratosis-like lesions\": \"benign\",\n",
    "        \"dermatofibroma\": \"benign\",\n",
    "        \"vascular lesions\": \"benign\",\n",
    "    }\n",
    "\n",
    "    labels = []\n",
    "    for img_name in image_files:\n",
    "        ann_path = os.path.join(ann_dir, img_name + \".json\")\n",
    "        try:\n",
    "            with open(ann_path, \"r\") as f:\n",
    "                ann = json.load(f)\n",
    "            original_label = ann[\"objects\"][0][\"classTitle\"]\n",
    "            group_label = group_map[original_label]\n",
    "            labels.append(group_label)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return Counter(labels)\n",
    "\n",
    "\n",
    "train_dist = get_class_distribution(train_files, ann_dir)\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "for label, count in train_dist.items():\n",
    "    print(f\"  {label}: {count} ({count/sum(train_dist.values())*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb0af5",
   "metadata": {},
   "source": [
    "## 3. Improved Model Architectures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9e083eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name=\"resnet50\", num_classes=3, pretrained=True):\n",
    "    \"\"\"\n",
    "    Create a model with transfer learning.\n",
    "\n",
    "    Supported architectures based on literature:\n",
    "    - resnet18, resnet50: Deep residual learning (He et al., 2016)\n",
    "    - efficientnet_b0, efficientnet_b3: Compound scaling (Tan & Le, 2019)\n",
    "    - densenet121: Dense connections (Huang et al., 2017)\n",
    "    \"\"\"\n",
    "\n",
    "    if model_name.startswith(\"resnet\"):\n",
    "        if model_name == \"resnet18\":\n",
    "            model = models.resnet18(pretrained=pretrained)\n",
    "        elif model_name == \"resnet50\":\n",
    "            model = models.resnet50(pretrained=pretrained)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported ResNet variant: {model_name}\")\n",
    "\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    elif model_name.startswith(\"efficientnet\"):\n",
    "        # Using timm library for EfficientNet\n",
    "        model = timm.create_model(model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "\n",
    "    elif model_name.startswith(\"densenet\"):\n",
    "        if model_name == \"densenet121\":\n",
    "            model = models.densenet121(pretrained=pretrained)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported DenseNet variant: {model_name}\")\n",
    "\n",
    "        num_ftrs = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958f383",
   "metadata": {},
   "source": [
    "## 4. Training Functions with Class Imbalance Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e9b494b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(dataset):\n",
    "    \"\"\"\n",
    "    Calculate class weights for weighted loss.\n",
    "    Inverse frequency weighting to handle class imbalance.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    for i in range(len(dataset)):\n",
    "        _, label = dataset[i]\n",
    "        labels.append(label)\n",
    "\n",
    "    class_counts = Counter(labels)\n",
    "    total = sum(class_counts.values())\n",
    "\n",
    "    # Inverse frequency weighting\n",
    "    weights = {cls: total / count for cls, count in class_counts.items()}\n",
    "\n",
    "    # Normalize weights\n",
    "    weight_sum = sum(weights.values())\n",
    "    weights = {cls: w / weight_sum * len(weights) for cls, w in weights.items()}\n",
    "\n",
    "    # Convert to tensor\n",
    "    weight_tensor = torch.tensor([weights[i] for i in range(len(weights))], dtype=torch.float32)\n",
    "\n",
    "    return weight_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac566ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch.\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in dataloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"Validate the model.\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9391c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, early_stopping_patience=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Full training loop with early stopping and best model checkpointing.\n",
    "    \"\"\"\n",
    "    best_val_acc = 0.0\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    patience_counter = 0\n",
    "\n",
    "    history = {\"train_loss\": [], \"train_acc\": [], \"val_loss\": [], \"val_acc\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(model, val_loader, criterion, device)\n",
    "\n",
    "        # Learning rate scheduling\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Record history\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "        # Check for best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            patience_counter = 0\n",
    "            print(f\"  âœ“ New best validation accuracy: {best_val_acc:.4f}\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        # Early stopping\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "\n",
    "    # Load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history, best_val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bbc6ff",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Optimization with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88979aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"\n",
    "    Optuna objective function for hyperparameter optimization.\n",
    "\n",
    "    PRIMARY METRIC: Melanoma Recall (Sensitivity)\n",
    "    - Optimizes for catching all melanoma cases (minimize false negatives)\n",
    "    - More clinically appropriate than overall accuracy\n",
    "    - Secondary consideration: balanced performance across all classes\n",
    "\n",
    "    Optimizes:\n",
    "    - Model architecture\n",
    "    - Learning rate\n",
    "    - Weight decay\n",
    "    - Batch size\n",
    "    - Augmentation level\n",
    "    \"\"\"\n",
    "\n",
    "    # Suggest hyperparameters\n",
    "    model_name = trial.suggest_categorical(\"model\", [\"resnet18\", \"resnet50\", \"efficientnet_b0\", \"densenet121\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-3, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-3, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64])\n",
    "    augmentation_level = trial.suggest_categorical(\"augmentation\", [\"light\", \"medium\", \"heavy\"])\n",
    "\n",
    "    # Determine input size based on model\n",
    "    input_size = 299 if \"efficientnet\" in model_name else 224\n",
    "\n",
    "    # Create datasets with selected augmentation\n",
    "    train_transform, val_transform = get_augmentation_transforms(augmentation_level, input_size)\n",
    "\n",
    "    train_dataset = HAM10000Dataset(image_dir, ann_dir, train_files, transform=train_transform)\n",
    "    val_dataset = HAM10000Dataset(image_dir, ann_dir, val_files, transform=val_transform)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Create model\n",
    "    model = create_model(model_name, num_classes=3, pretrained=True)\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Calculate class weights\n",
    "    class_weights = get_class_weights(train_dataset).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "    # Optimizer and scheduler\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n",
    "\n",
    "    # Train for limited epochs (hyperparameter search)\n",
    "    num_epochs = 10\n",
    "\n",
    "    try:\n",
    "        model, history, best_val_acc = train_model(\n",
    "            model,\n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            criterion,\n",
    "            optimizer,\n",
    "            scheduler,\n",
    "            num_epochs=num_epochs,\n",
    "            device=device,\n",
    "            early_stopping_patience=3,\n",
    "        )\n",
    "\n",
    "        # Evaluate on validation set to get melanoma recall\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for images, labels_batch in val_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                all_preds.extend(predicted.cpu().numpy())\n",
    "                all_labels.extend(labels_batch.numpy())\n",
    "\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "\n",
    "        # Calculate melanoma recall (class 2)\n",
    "        from sklearn.metrics import recall_score\n",
    "\n",
    "        melanoma_preds_binary = (all_preds == 2).astype(int)\n",
    "        melanoma_labels_binary = (all_labels == 2).astype(int)\n",
    "        melanoma_recall = recall_score(melanoma_labels_binary, melanoma_preds_binary, zero_division=0)\n",
    "\n",
    "        # Calculate macro recall for balance\n",
    "        macro_recall = recall_score(all_labels, all_preds, average=\"macro\", zero_division=0)\n",
    "\n",
    "        # Composite score: 70% melanoma recall + 30% macro recall\n",
    "        # This ensures we catch melanoma while maintaining reasonable overall performance\n",
    "        composite_score = 0.7 * melanoma_recall + 0.3 * macro_recall\n",
    "\n",
    "        print(\n",
    "            f\"  â†’ Melanoma Recall: {melanoma_recall:.4f}, Macro Recall: {macro_recall:.4f}, Composite: {composite_score:.4f}\"\n",
    "        )\n",
    "\n",
    "        return composite_score\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Trial failed with error: {e}\")\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dadf3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-18 18:40:20,728] A new study created in memory with name: melanoma_detection\n",
      "c:\\Users\\major\\Documents\\University\\DeepLearning\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "c:\\Users\\major\\Documents\\University\\DeepLearning\\.venv\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet121_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet121_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization with 3 trials...\n",
      "This may take several hours depending on your hardware.\n",
      "\n",
      "Downloading: \"https://download.pytorch.org/models/densenet121-a639ec97.pth\" to C:\\Users\\major/.cache\\torch\\hub\\checkpoints\\densenet121-a639ec97.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30.8M/30.8M [00:01<00:00, 16.6MB/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data/ham10000/ds/ann\\ISIC_0029819.jpg.json: list index out of range\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter optimization\n",
    "# Note: This will take significant time. Adjust n_trials based on your compute resources.\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", study_name=\"melanoma_detection\")\n",
    "\n",
    "# Run optimization with fewer trials for demonstration\n",
    "# Increase n_trials for more thorough search (recommended: 20-50 trials)\n",
    "n_trials = 3\n",
    "\n",
    "print(f\"Starting hyperparameter optimization with {n_trials} trials...\")\n",
    "print(\"PRIMARY METRIC: Melanoma Recall (70%) + Macro Recall (30%)\")\n",
    "print(\"This may take several hours depending on your hardware.\\n\")\n",
    "\n",
    "study.optimize(objective, n_trials=n_trials, timeout=None)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"Hyperparameter Optimization Complete!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nBest trial: {study.best_trial.number}\")\n",
    "print(f\"Best composite score (70% melanoma recall + 30% macro recall): {study.best_trial.value:.4f}\")\n",
    "print(f\"\\nBest hyperparameters:\")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ NOTE: This model is optimized for melanoma detection (recall-focused)\")\n",
    "print(\"   rather than overall accuracy. This is clinically appropriate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1d220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save detailed trial report to text file\n",
    "from datetime import datetime\n",
    "\n",
    "report_path = \"optuna_trials_report.txt\"\n",
    "\n",
    "with open(report_path, \"w\") as f:\n",
    "    # Header\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(\"HYPERPARAMETER OPTIMIZATION REPORT\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "    f.write(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Study Name: {study.study_name}\\n\")\n",
    "    f.write(f\"Direction: Maximize (Composite Score = 70% Melanoma Recall + 30% Macro Recall)\\n\")\n",
    "    f.write(f\"Total Trials: {len(study.trials)}\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "    # Best trial summary\n",
    "    f.write(\"BEST TRIAL SUMMARY\\n\")\n",
    "    f.write(\"-\" * 80 + \"\\n\")\n",
    "    f.write(f\"Trial Number: {study.best_trial.number}\\n\")\n",
    "    f.write(f\"Best Composite Score: {study.best_trial.value:.6f}\\n\")\n",
    "    f.write(f\"\\nBest Hyperparameters:\\n\")\n",
    "    for key, value in study.best_trial.params.items():\n",
    "        f.write(f\"  {key:20s}: {value}\\n\")\n",
    "    f.write(\"\\n\" + \"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "    # Detailed trial results\n",
    "    f.write(\"DETAILED TRIAL RESULTS\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "    for trial in study.trials:\n",
    "        f.write(f\"Trial #{trial.number}\\n\")\n",
    "        f.write(\"-\" * 80 + \"\\n\")\n",
    "        f.write(f\"Status: {trial.state.name}\\n\")\n",
    "\n",
    "        if trial.value is not None:\n",
    "            f.write(f\"Composite Score: {trial.value:.6f}\\n\")\n",
    "        else:\n",
    "            f.write(f\"Composite Score: FAILED\\n\")\n",
    "\n",
    "        f.write(f\"\\nHyperparameters:\\n\")\n",
    "        for key, value in trial.params.items():\n",
    "            f.write(f\"  {key:20s}: {value}\\n\")\n",
    "\n",
    "        # Duration\n",
    "        if trial.duration is not None:\n",
    "            duration_min = trial.duration.total_seconds() / 60\n",
    "            f.write(f\"\\nDuration: {duration_min:.2f} minutes\\n\")\n",
    "\n",
    "        # User attributes (if any custom metrics were stored)\n",
    "        if trial.user_attrs:\n",
    "            f.write(f\"\\nAdditional Metrics:\\n\")\n",
    "            for key, value in trial.user_attrs.items():\n",
    "                f.write(f\"  {key}: {value}\\n\")\n",
    "\n",
    "        f.write(\"\\n\" + \"=\" * 80 + \"\\n\\n\")\n",
    "\n",
    "    # Summary statistics\n",
    "    f.write(\"SUMMARY STATISTICS\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    completed_trials = [t for t in study.trials if t.value is not None]\n",
    "    if completed_trials:\n",
    "        scores = [t.value for t in completed_trials]\n",
    "        f.write(f\"Completed Trials: {len(completed_trials)}/{len(study.trials)}\\n\")\n",
    "        f.write(f\"Best Score: {max(scores):.6f}\\n\")\n",
    "        f.write(f\"Worst Score: {min(scores):.6f}\\n\")\n",
    "        f.write(f\"Mean Score: {np.mean(scores):.6f}\\n\")\n",
    "        f.write(f\"Std Dev: {np.std(scores):.6f}\\n\")\n",
    "\n",
    "    f.write(\"\\n\" + \"=\" * 80 + \"\\n\")\n",
    "    f.write(\"END OF REPORT\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "print(f\"âœ“ Detailed trial report saved to: {report_path}\")\n",
    "print(f\"  Total trials documented: {len(study.trials)}\")\n",
    "print(f\"  Best trial: #{study.best_trial.number} with score {study.best_trial.value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888ce008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize optimization history\n",
    "fig = optuna.visualization.plot_optimization_history(study)\n",
    "fig.show()\n",
    "\n",
    "fig = optuna.visualization.plot_param_importances(study)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8262920f",
   "metadata": {},
   "source": [
    "## 6. Train Final Model with Best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a5c6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best hyperparameters\n",
    "best_params = study.best_trial.params\n",
    "print(\"Training final model with best hyperparameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Setup with best parameters\n",
    "model_name = best_params[\"model\"]\n",
    "lr = best_params[\"lr\"]\n",
    "weight_decay = best_params[\"weight_decay\"]\n",
    "batch_size = best_params[\"batch_size\"]\n",
    "augmentation_level = best_params[\"augmentation\"]\n",
    "\n",
    "input_size = 299 if \"efficientnet\" in model_name else 224\n",
    "\n",
    "# Create datasets\n",
    "train_transform, val_transform = get_augmentation_transforms(augmentation_level, input_size)\n",
    "\n",
    "train_dataset = HAM10000Dataset(image_dir, ann_dir, train_files, transform=train_transform)\n",
    "val_dataset = HAM10000Dataset(image_dir, ann_dir, val_files, transform=val_transform)\n",
    "test_dataset = HAM10000Dataset(image_dir, ann_dir, test_files, transform=val_transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "# Create model\n",
    "final_model = create_model(model_name, num_classes=3, pretrained=True)\n",
    "final_model = final_model.to(device)\n",
    "\n",
    "# Setup training\n",
    "class_weights = get_class_weights(train_dataset).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.AdamW(final_model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "\n",
    "# Train with more epochs for final model\n",
    "print(\"\\nTraining final model...\")\n",
    "final_model, history, best_val_acc = train_model(\n",
    "    final_model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=30,\n",
    "    device=device,\n",
    "    early_stopping_patience=7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13cb6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Loss plot\n",
    "ax1.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "ax1.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.set_title(\"Training and Validation Loss\")\n",
    "ax1.legend()\n",
    "ax1.grid(True)\n",
    "\n",
    "# Accuracy plot\n",
    "ax2.plot(history[\"train_acc\"], label=\"Train Acc\")\n",
    "ax2.plot(history[\"val_acc\"], label=\"Val Acc\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Accuracy\")\n",
    "ax2.set_title(\"Training and Validation Accuracy\")\n",
    "ax2.legend()\n",
    "ax2.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"training_history.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef33b2bc",
   "metadata": {},
   "source": [
    "## 7. Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2042e",
   "metadata": {},
   "source": [
    "### Clinical Metrics: Why Recall Matters\n",
    "\n",
    "For melanoma detection, **Recall (Sensitivity)** is the most critical metric:\n",
    "\n",
    "**ðŸ”´ High Recall for Melanoma is CRITICAL**:\n",
    "- **False Negative** (missing melanoma) = Patient doesn't get treatment â†’ Life-threatening\n",
    "- **False Positive** (incorrectly flagging benign as melanoma) = Unnecessary doctor visit â†’ Inconvenient but safe\n",
    "\n",
    "**Clinical Priority**:\n",
    "1. **Melanoma Recall** â†’ Maximize (catch all dangerous cases, even with false positives)\n",
    "2. **Suspicious Recall** â†’ High (better safe than sorry)\n",
    "3. **Benign Precision** â†’ Moderate (avoid unnecessary anxiety, but safety first)\n",
    "\n",
    "**Trade-off**: We prefer 95% melanoma recall with 80% accuracy over 90% accuracy with 70% melanoma recall.\n",
    "\n",
    "This is why we'll use **weighted recall** or **melanoma-specific recall** as our optimization metric instead of overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55201fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Comprehensive model evaluation with metrics.\"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            probs = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    return np.array(all_preds), np.array(all_labels), np.array(all_probs)\n",
    "\n",
    "\n",
    "# Evaluate\n",
    "preds, labels, probs = evaluate_model(final_model, test_loader, device)\n",
    "\n",
    "# Calculate metrics\n",
    "test_acc = accuracy_score(labels, preds)\n",
    "print(f\"\\nTest Accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "class_names = [\"benign\", \"suspicious\", \"melanoma\"]\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(labels, preds, target_names=class_names, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(labels, preds)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43af494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate detailed clinical metrics with emphasis on Recall\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score, roc_auc_score\n",
    "\n",
    "# Per-class metrics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLINICAL METRICS - RECALL FOCUSED\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_preds_binary = (preds == i).astype(int)\n",
    "    class_labels_binary = (labels == i).astype(int)\n",
    "\n",
    "    recall = recall_score(class_labels_binary, class_preds_binary)\n",
    "    precision = precision_score(class_labels_binary, class_preds_binary, zero_division=0)\n",
    "    f1 = f1_score(class_labels_binary, class_preds_binary, zero_division=0)\n",
    "\n",
    "    print(f\"\\n{class_name.upper()}:\")\n",
    "    print(f\"  Recall (Sensitivity): {recall:.4f} â­ {'CRITICAL!' if class_name == 'melanoma' else ''}\")\n",
    "    print(f\"  Precision:            {precision:.4f}\")\n",
    "    print(f\"  F1-Score:             {f1:.4f}\")\n",
    "    print(f\"  Support:              {np.sum(labels == i)}\")\n",
    "\n",
    "# Calculate macro and weighted recall\n",
    "macro_recall = recall_score(labels, preds, average=\"macro\")\n",
    "weighted_recall = recall_score(labels, preds, average=\"weighted\")\n",
    "melanoma_recall = recall_score((labels == 2).astype(int), (preds == 2).astype(int))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"Overall Accuracy:         {test_acc:.4f}\")\n",
    "print(f\"Macro Recall (avg):       {macro_recall:.4f}\")\n",
    "print(f\"Weighted Recall:          {weighted_recall:.4f}\")\n",
    "print(f\"ðŸ”´ MELANOMA RECALL:        {melanoma_recall:.4f} â† PRIMARY METRIC\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Clinical interpretation\n",
    "if melanoma_recall >= 0.95:\n",
    "    print(\"\\nâœ… EXCELLENT: Melanoma recall â‰¥95% - Clinically acceptable\")\n",
    "elif melanoma_recall >= 0.90:\n",
    "    print(\"\\nâœ“ GOOD: Melanoma recall â‰¥90% - Acceptable with monitoring\")\n",
    "elif melanoma_recall >= 0.85:\n",
    "    print(\"\\nâš  WARNING: Melanoma recall <90% - Needs improvement\")\n",
    "else:\n",
    "    print(\"\\nâŒ CRITICAL: Melanoma recall <85% - NOT clinically safe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38fdb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.title(\"Confusion Matrix - Improved Model\")\n",
    "plt.savefig(\"confusion_matrix_improved.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851d7ae0",
   "metadata": {},
   "source": [
    "## 8. Save Improved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f53917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model weights\n",
    "model_save_path = \"melanoma_model_improved_weights.pth\"\n",
    "torch.save(final_model.state_dict(), model_save_path)\n",
    "print(f\"âœ“ Model weights saved to {model_save_path}\")\n",
    "\n",
    "# Save model configuration and results\n",
    "results = {\n",
    "    \"model_architecture\": model_name,\n",
    "    \"input_size\": input_size,\n",
    "    \"num_classes\": 3,\n",
    "    \"best_hyperparameters\": best_params,\n",
    "    \"best_val_accuracy\": float(best_val_acc),\n",
    "    \"test_accuracy\": float(test_acc),\n",
    "    \"class_names\": class_names,\n",
    "    \"training_history\": {\n",
    "        \"train_loss\": [float(x) for x in history[\"train_loss\"]],\n",
    "        \"val_loss\": [float(x) for x in history[\"val_loss\"]],\n",
    "        \"train_acc\": [float(x) for x in history[\"train_acc\"]],\n",
    "        \"val_acc\": [float(x) for x in history[\"val_acc\"]],\n",
    "    },\n",
    "}\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"model_results_improved.json\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)\n",
    "\n",
    "print(\"âœ“ Model configuration and results saved to model_results_improved.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef6b604",
   "metadata": {},
   "source": [
    "## 9. Compare with Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afad3ff",
   "metadata": {},
   "source": [
    "## Experimental Results & Model Comparison\n",
    "\n",
    "### Models Evaluated\n",
    "\n",
    "We systematically evaluated multiple state-of-the-art architectures through hyperparameter optimization:\n",
    "\n",
    "#### 1. **ResNet18** (Baseline)\n",
    "- **Architecture**: He et al., 2016 - \"Deep Residual Learning for Image Recognition\"\n",
    "- **Why chosen**: Proven baseline for medical imaging, good balance of performance and speed\n",
    "- **Parameters**: ~11M\n",
    "- **Key features**: 18 layers with residual connections\n",
    "- **Expected use**: Fast inference, baseline comparison\n",
    "\n",
    "#### 2. **ResNet50**\n",
    "- **Architecture**: He et al., 2016 - Deeper variant of ResNet\n",
    "- **Why chosen**: More capacity for complex pattern recognition in skin lesions\n",
    "- **Parameters**: ~25M\n",
    "- **Key features**: 50 layers, bottleneck architecture\n",
    "- **Expected use**: Improved accuracy over ResNet18 with moderate computational cost\n",
    "\n",
    "#### 3. **EfficientNet-B0**\n",
    "- **Architecture**: Tan & Le, 2019 - \"EfficientNet: Rethinking Model Scaling for CNNs\"\n",
    "- **Why chosen**: State-of-the-art efficiency, compound scaling of depth/width/resolution\n",
    "- **Parameters**: ~5M\n",
    "- **Key features**: Optimized architecture through NAS, excellent parameter efficiency\n",
    "- **Expected use**: Best accuracy-to-efficiency ratio\n",
    "\n",
    "#### 4. **DenseNet121**\n",
    "- **Architecture**: Huang et al., 2017 - \"Densely Connected Convolutional Networks\"\n",
    "- **Why chosen**: Dense connections promote feature reuse, good for medical imaging\n",
    "- **Parameters**: ~8M\n",
    "- **Key features**: Each layer receives gradients from all previous layers\n",
    "- **Expected use**: Strong gradient flow, efficient feature learning\n",
    "\n",
    "---\n",
    "\n",
    "### Hyperparameter Optimization Results\n",
    "\n",
    "**Optimization Strategy**: Optuna Tree-structured Parzen Estimator (TPE)\n",
    "\n",
    "**Search Space**:\n",
    "- **Models**: [ResNet18, ResNet50, EfficientNet-B0, DenseNet121]\n",
    "- **Learning Rate**: [1e-5, 1e-3] (log scale)\n",
    "- **Weight Decay**: [1e-6, 1e-3] (log scale)\n",
    "- **Batch Size**: [16, 32, 64]\n",
    "- **Augmentation**: [light, medium, heavy]\n",
    "\n",
    "**Number of Trials**: _[Fill in after running]_\n",
    "\n",
    "**Best Hyperparameters Found**:\n",
    "```\n",
    "Model: [To be filled after optimization]\n",
    "Learning Rate: [To be filled]\n",
    "Weight Decay: [To be filled]\n",
    "Batch Size: [To be filled]\n",
    "Augmentation Level: [To be filled]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Performance Summary\n",
    "\n",
    "| Model | Val Accuracy | Test Accuracy | Params | Training Time | Notes |\n",
    "|-------|-------------|---------------|--------|---------------|-------|\n",
    "| ResNet18 (baseline) | _TBD_ | _TBD_ | 11M | ~X min | Baseline model |\n",
    "| ResNet50 | _TBD_ | _TBD_ | 25M | ~X min | _Add notes after training_ |\n",
    "| EfficientNet-B0 | _TBD_ | _TBD_ | 5M | ~X min | _Add notes after training_ |\n",
    "| DenseNet121 | _TBD_ | _TBD_ | 8M | ~X min | _Add notes after training_ |\n",
    "| **Best Model** | **_TBD_** | **_TBD_** | **_TBD_** | **~X min** | **Selected via Optuna** |\n",
    "\n",
    "---\n",
    "\n",
    "### Per-Class Performance (Best Model)\n",
    "\n",
    "| Class | Precision | Recall | F1-Score | Support |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| Benign | _TBD_ | _TBD_ | _TBD_ | _TBD_ |\n",
    "| Suspicious | _TBD_ | _TBD_ | _TBD_ | _TBD_ |\n",
    "| Melanoma | _TBD_ | _TBD_ | _TBD_ | _TBD_ |\n",
    "\n",
    "**Key Observations**:\n",
    "- _[Add observations about which classes are hardest to predict]_\n",
    "- _[Note any confusion patterns between classes]_\n",
    "- _[Comment on clinical implications]_\n",
    "\n",
    "---\n",
    "\n",
    "### Key Insights from Optimization\n",
    "\n",
    "**Most Important Hyperparameters** (from Optuna importance analysis):\n",
    "1. _[To be filled after running plot_param_importances]_\n",
    "2. _[...]_\n",
    "3. _[...]_\n",
    "\n",
    "**Findings**:\n",
    "- **Data Augmentation**: _[Effect of augmentation level on performance]_\n",
    "- **Model Capacity**: _[Trade-off between model size and accuracy]_\n",
    "- **Learning Rate**: _[Optimal range found]_\n",
    "- **Batch Size**: _[Impact on convergence and generalization]_\n",
    "\n",
    "**Clinical Relevance**:\n",
    "- **Sensitivity for Melanoma**: _[Critical metric for dangerous cases]_\n",
    "- **Specificity for Benign**: _[Avoid unnecessary patient anxiety]_\n",
    "- **Suspicious Cases**: _[Balance between caution and over-referral]_\n",
    "\n",
    "---\n",
    "\n",
    "### Recommendations from Results\n",
    "\n",
    "Based on experimental results:\n",
    "\n",
    "1. **Production Model**: _[Best model recommendation]_\n",
    "2. **Deployment Trade-offs**: \n",
    "   - For **mobile/edge devices**: EfficientNet-B0 (smaller, faster)\n",
    "   - For **cloud/server**: ResNet50 or best Optuna model (highest accuracy)\n",
    "3. **Ensemble Strategy**: Consider averaging top 3 models for 1-3% accuracy boost\n",
    "4. **Threshold Tuning**: Adjust decision thresholds based on class-specific requirements\n",
    "\n",
    "---\n",
    "\n",
    "**Last Updated**: _[Add date after completing experiments]_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3328ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate baseline model on same test set\n",
    "if os.path.exists(\"melanoma_model_weights.pth\"):\n",
    "    print(\"Evaluating baseline ResNet18 model...\")\n",
    "    baseline_preds, baseline_labels, _ = evaluate_model(baseline_model, test_loader, device)\n",
    "    baseline_acc = accuracy_score(baseline_labels, baseline_preds)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"MODEL COMPARISON\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Baseline ResNet18 Test Accuracy: {baseline_acc:.4f}\")\n",
    "    print(f\"Improved {model_name} Test Accuracy: {test_acc:.4f}\")\n",
    "    print(f\"Improvement: {(test_acc - baseline_acc):.4f} ({(test_acc - baseline_acc)/baseline_acc*100:.2f}%)\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    print(\"âš  Baseline model not found for comparison\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72144a92",
   "metadata": {},
   "source": [
    "## 10. Next Steps and Recommendations\n",
    "\n",
    "### Further Improvements:\n",
    "\n",
    "1. **Ensemble Methods**:\n",
    "   - Train multiple models (ResNet50, EfficientNet, DenseNet)\n",
    "   - Average predictions for improved robustness\n",
    "   - Research shows 2-5% accuracy gains (Haenssle et al., 2018)\n",
    "\n",
    "2. **Advanced Augmentation**:\n",
    "   - Implement MixUp (Zhang et al., 2018)\n",
    "   - Try CutMix (Yun et al., 2019)\n",
    "   - Test AutoAugment strategies\n",
    "\n",
    "3. **Test-Time Augmentation (TTA)**:\n",
    "   - Apply augmentations during inference\n",
    "   - Average predictions across augmented versions\n",
    "   - Typically improves accuracy by 1-3%\n",
    "\n",
    "4. **Focal Loss Implementation**:\n",
    "   - Replace CrossEntropyLoss with Focal Loss\n",
    "   - Better handles hard examples\n",
    "   - Particularly useful for medical imaging\n",
    "\n",
    "5. **Attention Mechanisms**:\n",
    "   - Add attention modules (CBAM, SE-Net)\n",
    "   - Helps model focus on lesion regions\n",
    "   - Improves interpretability\n",
    "\n",
    "6. **Multi-Task Learning**:\n",
    "   - Predict both 3-class groups and original 7 classes\n",
    "   - Auxiliary tasks can improve feature learning\n",
    "\n",
    "7. **External Validation**:\n",
    "   - Test on ISIC2020 dataset\n",
    "   - Evaluate generalization to different data distributions\n",
    "\n",
    "### Deployment Considerations:\n",
    "\n",
    "- **Model Compression**: Use pruning or quantization for mobile deployment\n",
    "- **ONNX Export**: Convert to ONNX for cross-platform inference\n",
    "- **API Development**: Create REST API with FastAPI or Flask\n",
    "- **Monitoring**: Track prediction distributions in production\n",
    "- **Regulatory**: Consider FDA/CE marking requirements for medical devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c67be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TRAINING COMPLETE - SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nBest Model: {model_name}\")\n",
    "print(f\"Input Size: {input_size}x{input_size}\")\n",
    "print(f\"Augmentation: {augmentation_level}\")\n",
    "print(f\"Learning Rate: {lr:.6f}\")\n",
    "print(f\"Weight Decay: {weight_decay:.6f}\")\n",
    "print(f\"Batch Size: {batch_size}\")\n",
    "print(f\"\\nFinal Test Accuracy: {test_acc:.4f}\")\n",
    "print(f\"\\nModel saved to: {model_save_path}\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
